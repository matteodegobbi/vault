{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq7MqgGKBfOq"
   },
   "source": [
    "# MNIST Digit Classification with a Convolutional Neural Network (CNN)\n",
    "*By Carlos Santiago Bañón*\n",
    "\n",
    "**Year:** 2020\n",
    "\n",
    "**Technologies:** Python, NumPy, Matplotlib, TensforFlow, Keras\n",
    "\n",
    "**Discipline(s):** Computer Vision, Deep Learning\n",
    "\n",
    "**Keywords:** `classification`, `cnn`, `computer-vision`, `convolution`, `convolutional-neural-network`, `deep-learning`, `fully-connected`, `max-pooling`, `mnist`, `multi-class-classification`, `neural-network`, `2d-convolution`, `2d-max-pooling`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSmvrCh8CqZq"
   },
   "source": [
    "This notebook presents an MNIST digit classifier built with a convolutional neural network (CNN) in TensorFlow and Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uzlnsvf1DGpk"
   },
   "source": [
    "## 1. Import Statements\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "l8DhknOWDIc4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:21:36.754538: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-07 14:21:36.842420: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-07 14:21:36.863987: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-07 14:21:37.306514: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fogliodicarta/miniconda3/envs/tesi/lib/\n",
      "2023-11-07 14:21:37.306560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fogliodicarta/miniconda3/envs/tesi/lib/\n",
      "2023-11-07 14:21:37.306563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yuvx7u4qDQ0p"
   },
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qI70NJ8SN4An"
   },
   "source": [
    "The first step is to preprocess our data. Here, we load the MNIST digit dataset from the Keras datasets library, split it into training and test sets, reshape the matrices, and encode the labels categorically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IsaUq1mDDVLT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the MNIST dataset.\n",
    "mnist = tf.keras.datasets.mnist\n",
    "train_data, test_data = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nWuEpda6EBMN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Divide the data into features and labels.\n",
    "train_images, train_labels = train_data\n",
    "\n",
    "test_images, test_labels = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "p = 1\n",
    "chance_del_number = np.random.choice(a=[False, True], size=60000, p=[p, 1-p])  \n",
    "train_images = np.delete(train_images, np.where((train_labels == 8) & chance_del_number)[0], axis=0)\n",
    "train_labels = np.delete(train_labels, np.where((train_labels == 8) & chance_del_number), axis=0)\n",
    "print(type(train_images))\n",
    "permutation = np.random.permutation(len(train_images))\n",
    "train_images = train_images[permutation]\n",
    "train_labels = train_labels[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]))\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(np.unique(train_labels,return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET DATASET SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_SIZE=60000\n",
    "train_images = train_images[:DATASET_SIZE]\n",
    "train_labels = train_labels[:DATASET_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wrAabZnyDinP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape and normalize the images.\n",
    "X_train = train_images.reshape((DATASET_SIZE, 28, 28, 1))\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = test_images.reshape((10000, 28, 28, 1))\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iHUWJlyBE1P0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape the labels and encode them categorically.\n",
    "y_train = tf.keras.utils.to_categorical(train_labels)\n",
    "y_test = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVEOuuLPOJVH"
   },
   "source": [
    "Further, the following are the shapes of each matrix, as well as a visualization of a random MNIST digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PpPi0qpNI_L",
    "outputId": "2428ad46-a10d-4308-fa10-b214594127c6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images: (60000, 28, 28, 1)\n",
      "Testing Images: (10000, 28, 28, 1)\n",
      "Training Labels: (60000, 10)\n",
      "Test Labels: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Show the shapes of the data.\n",
    "print(\"Training Images:\", X_train.shape)\n",
    "print(\"Testing Images:\", X_test.shape)\n",
    "print(\"Training Labels:\", y_train.shape)\n",
    "print(\"Test Labels:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "mSKjBaeNNc1m",
    "outputId": "d46bf1c0-d366-4eee-8c21-993286d67f68",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a sample MNIST digit.\n",
    "plt.imshow(train_images[10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5ubfhUsFLR8"
   },
   "source": [
    "## 3. Convolutional Neural Network (CNN)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gPoq2dRFtrH"
   },
   "source": [
    "### 3.1. Define the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jU5sDVjhOVgF"
   },
   "source": [
    "We then have to define our convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ri1rSpp3FSDS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:21:38.188287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:21:38.192083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:21:38.192196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:21:38.192687: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-07 14:21:38.193206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:21:38.193318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:21:38.193381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:21:39.887235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:21:39.887349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:21:39.887406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-07 14:21:39.887459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 217 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Define the sequential model.\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5CNJ9gHWFWQv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the convolutional neural network.\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdMaLgtqFeV6",
    "outputId": "ef4b44ba-ff64-4f43-f2a2-1e98754f4c2a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYactRmuOhCW"
   },
   "source": [
    "Once our model is defined, we can compile it using the Adam optimizer and the categorical cross-entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "57j-R0L4Fmmf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRVabAG8F3IL"
   },
   "source": [
    "### 3.2. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IuRzsr2Osga"
   },
   "source": [
    "We then train the model on 10 epochs, using a batch size of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yl1f9mvZF5Pc",
    "outputId": "5d1869e2-2978-4acd-85f3-6d8c45fcf74f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:21:50.123207: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29MiB (rounded to 2400000)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-11-07 14:21:50.123231: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2023-11-07 14:21:50.123236: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 20, Chunks in use: 20. 5.0KiB allocated for chunks. 5.0KiB in use in bin. 1004B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123240: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123243: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 2, Chunks in use: 2. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 2.1KiB client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123245: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 1, Chunks in use: 1. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 2.5KiB client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123247: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 1, Chunks in use: 0. 4.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123249: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123251: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123254: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123257: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 1, Chunks in use: 1. 72.0KiB allocated for chunks. 72.0KiB in use in bin. 72.0KiB client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123260: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 4, Chunks in use: 2. 567.8KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123262: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123264: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123266: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123268: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123270: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123272: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123274: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123276: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123278: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123284: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 1. 217.24MiB allocated for chunks. 217.24MiB in use in bin. 179.44MiB client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123286: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-07 14:21:50.123288: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 2.29MiB was 2.00MiB, Chunk State: \n",
      "2023-11-07 14:21:50.123292: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 228458496\n",
      "2023-11-07 14:21:50.123296: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce000000 of size 256 next 1\n",
      "2023-11-07 14:21:50.123298: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce000100 of size 1280 next 2\n",
      "2023-11-07 14:21:50.123300: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce000600 of size 256 next 3\n",
      "2023-11-07 14:21:50.123302: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce000700 of size 256 next 4\n",
      "2023-11-07 14:21:50.123303: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce000800 of size 256 next 6\n",
      "2023-11-07 14:21:50.123305: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce000900 of size 256 next 7\n",
      "2023-11-07 14:21:50.123306: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce000a00 of size 256 next 5\n",
      "2023-11-07 14:21:50.123308: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce000b00 of size 256 next 8\n",
      "2023-11-07 14:21:50.123310: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce000c00 of size 256 next 13\n",
      "2023-11-07 14:21:50.123311: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce000d00 of size 256 next 11\n",
      "2023-11-07 14:21:50.123313: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce000e00 of size 256 next 12\n",
      "2023-11-07 14:21:50.123315: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce000f00 of size 256 next 16\n",
      "2023-11-07 14:21:50.123316: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce001000 of size 256 next 17\n",
      "2023-11-07 14:21:50.123318: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce001100 of size 256 next 20\n",
      "2023-11-07 14:21:50.123319: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce001200 of size 256 next 21\n",
      "2023-11-07 14:21:50.123321: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce001300 of size 256 next 22\n",
      "2023-11-07 14:21:50.123323: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce001400 of size 256 next 9\n",
      "2023-11-07 14:21:50.123324: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce001500 of size 1280 next 10\n",
      "2023-11-07 14:21:50.123326: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce001a00 of size 256 next 25\n",
      "2023-11-07 14:21:50.123328: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce001b00 of size 256 next 26\n",
      "2023-11-07 14:21:50.123329: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce001c00 of size 256 next 24\n",
      "2023-11-07 14:21:50.123331: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce001d00 of size 256 next 27\n",
      "2023-11-07 14:21:50.123332: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f31ce001e00 of size 4864 next 28\n",
      "2023-11-07 14:21:50.123334: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce003100 of size 2560 next 29\n",
      "2023-11-07 14:21:50.123336: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f31ce003b00 of size 139008 next 15\n",
      "2023-11-07 14:21:50.123338: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce025a00 of size 73728 next 14\n",
      "2023-11-07 14:21:50.123340: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f31ce037a00 of size 147456 next 19\n",
      "2023-11-07 14:21:50.123342: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce05ba00 of size 147456 next 18\n",
      "2023-11-07 14:21:50.123344: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce07fa00 of size 147456 next 23\n",
      "2023-11-07 14:21:50.123346: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f31ce0a3a00 of size 227788288 next 18446744073709551615\n",
      "2023-11-07 14:21:50.123348: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2023-11-07 14:21:50.123351: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 20 Chunks of size 256 totalling 5.0KiB\n",
      "2023-11-07 14:21:50.123353: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2023-11-07 14:21:50.123355: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 2560 totalling 2.5KiB\n",
      "2023-11-07 14:21:50.123357: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 73728 totalling 72.0KiB\n",
      "2023-11-07 14:21:50.123360: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 147456 totalling 288.0KiB\n",
      "2023-11-07 14:21:50.123362: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 227788288 totalling 217.24MiB\n",
      "2023-11-07 14:21:50.123364: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 217.60MiB\n",
      "2023-11-07 14:21:50.123365: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 228458496 memory_limit_: 228458496 available bytes: 0 curr_region_allocation_bytes_: 456916992\n",
      "2023-11-07 14:21:50.123370: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                       228458496\n",
      "InUse:                       228167168\n",
      "MaxInUse:                    228167168\n",
      "NumAllocs:                          52\n",
      "MaxAllocSize:                227788288\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-11-07 14:21:50.123373: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ***********************************************************************************xxxxxxxxxxxxxxxxx\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Train the model.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                      \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tesi/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tesi/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# Define the parameters.\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Train the model.\n",
    "history = model.fit(X_train, \n",
    "                      y_train, \n",
    "                      epochs=num_epochs, \n",
    "                      batch_size=batch_size, \n",
    "                      validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhyG0-sPHOAv"
   },
   "source": [
    "### 3.3. Display the Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhr5Aa5yfIsq"
   },
   "source": [
    "Finally, we display the metrics. We begin by displaying the model's accuracy and loss based on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFoIAPdSYXqh",
    "outputId": "14453be0-edc3-4387-f87b-ba6a6a30201d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "print('Test Loss:', test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ol-9qFvyfIsw"
   },
   "source": [
    "Then, we save the metric values for each epoch to plot the loss and accuracy curves for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjKFh83CfIsw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the metrics.\n",
    "metrics = history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZztnSHgjZPDN"
   },
   "source": [
    "Finally, once we have our metric history, we can plot the curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p56cSX3JfIsz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the loss values.\n",
    "training_loss_list = metrics['loss']\n",
    "test_loss_list = metrics['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "HKAZlyOmHV6f",
    "outputId": "6c2c9eaa-22e8-46cd-9689-5f293f45b764",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the training and test loss.\n",
    "x = np.arange(0, num_epochs, 1)\n",
    "plt.title('Training and Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(x, training_loss_list, label='Training Loss')\n",
    "plt.plot(x, test_loss_list, label='Test Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwzIUzuuI0ZP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_accuracy_list = metrics['accuracy']\n",
    "test_accuracy_list = metrics['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "kHj-j2HpI2Lb",
    "outputId": "2b1e8b66-5244-4c46-a375-f65d865476cf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Training and Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(x, train_accuracy_list, label='Training Accuracy')\n",
    "plt.plot(x, test_accuracy_list, label='Test Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2BDwaUigDgC"
   },
   "source": [
    "## 4. Make a Prediction\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vx34e_AWgLeE"
   },
   "source": [
    "Once our model is trained, we can use it to make predictions. To do this, we first use our test set to predict the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SylCmq61gTnM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions with the trained model.\n",
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMo9sEZpggPq"
   },
   "source": [
    "Finally, we can show a random test image with its corresponding prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "Gc6bx2stgfiY",
    "outputId": "91b62b84-eba4-49a8-b4be-09c5b4ce70ff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose an index.\n",
    "index = 128\n",
    "\n",
    "# Show an image from the test set.\n",
    "plt.imshow(test_images[index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bmSdfcFgunA",
    "outputId": "5c031a37-d8fa-4ea7-b173-466d23e25947",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Prediction:\", np.argmax(predictions[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "top1_predictions=[np.argmax(preds) for preds in predictions]\n",
    "correct_test_labels=[np.argmax(label) for label in y_test]\n",
    "unique, counts = np.unique(correct_test_labels, return_counts=True)\n",
    "#Create confusion matrix and normalizes it over predicted (columns)\n",
    "#conf_matr = multilabel_confusion_matrix(y_test, top1_predictions)\n",
    "conf_matrix=np.zeros((10,10),dtype=np.float64)\n",
    "for i,y_i in enumerate(correct_test_labels):\n",
    "    conf_matrix[y_i,top1_predictions[i]]+=1\n",
    "\n",
    "for i in range(10):\n",
    "    conf_matrix[i]=conf_matrix[i]/float(counts[i])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "conf_matrix\n",
    "df = pd.DataFrame(conf_matrix, columns = [i for i in range(10)], index=[i for i in range(10)])\n",
    "\n",
    "def highlight_cells(s):\n",
    "    index_max=s.idxmax()\n",
    "    s2=s.to_numpy()\n",
    "    #[0:index_max]+s[index_max+1:]\n",
    "    #print(s)\n",
    "    \n",
    "    s2=(np.concatenate((s2[0:index_max],[-1],s2[index_max+1:])))\n",
    "    #print(s2)\n",
    "    second_index_max = s2.argmax()\n",
    "    #print(second_index_max)\n",
    "    color = 'grey'\n",
    "    return ['background-color: %s' % \"#FF3131\"if i==index_max else 'background-color: %s' % \"coral\" if i==second_index_max else 'background-color: %s' % \"#e5e8ec\" for i in range(10)]\n",
    "df=df.style.apply(highlight_cells,axis=1).format(precision=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top1_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(y_test)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def KL(P,Q):\n",
    "     \"\"\" Epsilon is used here to avoid conditional code for\n",
    "     checking that neither P nor Q is equal to 0. \"\"\"\n",
    "     epsilon = 0.00001\n",
    "\n",
    "     # You may want to instead make copies to avoid changing the np arrays.\n",
    "     P = P+epsilon\n",
    "     Q = Q+epsilon\n",
    "\n",
    "     divergence = np.sum(P*np.log(P/Q))\n",
    "     return divergence\n",
    "\n",
    "#READ GENERATED IMAGES\n",
    "CODICE_RUN = \"l128\"\n",
    "generated_images_path = f\"/home/fogliodicarta/Desktop/vault/programmiTesi/GAN_target/{CODICE_RUN}whitebox/{CODICE_RUN}\"\n",
    "ds=tf.keras.utils.image_dataset_from_directory(generated_images_path,color_mode=\"grayscale\",label_mode=None,batch_size=1,image_size=(28,28))\n",
    "iteratorDS=ds.as_numpy_iterator()\n",
    "arr=np.fromiter(iteratorDS,np.dtype(\"(28,28,1)f4\"))\n",
    "print(arr.shape)\n",
    "#COMPUTE PREDICTIONS\n",
    "generated_predictions = model.predict(arr)\n",
    "#COMPUTE MARGINAL PROBS\n",
    "marginal_probs = np.zeros(10)\n",
    "for i in range(len(generated_predictions)):\n",
    "    for digit in range(10):\n",
    "        marginal_probs[digit]+=generated_predictions[i,digit]\n",
    "normalization_coeff_marginal = marginal_probs.sum()\n",
    "print(marginal_probs)\n",
    "print(marginal_probs/normalization_coeff_marginal)\n",
    "ERRORE PROBABILMENTE E' DA NORMALIZZARE ROBA   '\n",
    "KLbyClass = np.zeros(10)\n",
    "for i in range(len(generated_predictions)):\n",
    "    KLbyClass+=KL(marginal_probs,generated_predictions[i])\n",
    "KLbyClass.mean()\n",
    "IS=np.exp(KLbyClass)\n",
    "f = open(f\"IS{CODICE_RUN}.txt\", \"w\")\n",
    "f.write(f\"{IS}\")\n",
    "f.close()\n",
    "'''  \n",
    "# Should be normalized though\n",
    "values1 = np.asarray([1.346112,1.337432,1.246655])\n",
    "values2 = np.asarray([1.033836,1.082015,1.117323])\n",
    "\n",
    "# Note slight difference in the final result compared to Dawny33\n",
    "print KL(values1, values2) # 0.775278939433'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asdasd=(generated_predictions[generated_predictions!=0])#generated_predictions!=1]\n",
    "asdasd=asdasd[asdasd!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "7.41463482e-01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPmzXHjccEkM4rtZ/PEIMoD",
   "name": "MNIST Digit Classification with a Convolutional Neural Network (CNN)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
