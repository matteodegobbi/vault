* LBP
* Dissimilarity space
* FP, FN, Precision, Recall, F-Score ecc
* mAP, AUC
* one-error, hamming loss
* Test statistici
* bias-variance tradeoff
* Perceptron, McCulloch, Sigmoid, tanh
* MLP
* Backprop per MLP con squared loss e 3 layers
* SGD
* Softmax e Cross-Entropy, BCE
* Regularization
* Learning rate, annealing, momentum, one-cycle
* Adam, DiffGrad
* Dropout
* Deep networks
* Vanishing gradient, Xavier init
* CNN, conv, 1x1 conv, invariance to translation
* ReLU, LeakyReLU, ELU, PReLu, APLU ...
* Pooling
* Gradient of loss function, Jacobian (parte di Jeremy Howard)
* AlexNet, GoogleNet, DenseNet
* Autodiff
* Transfer learning e AEs
* Adv examples e Distribution shift
* RL, Q learning e Deep Q networks
* RNN, LSTM, GRU, TCN
* GANs
* Siamese nets: triplet, contrastive
* Segmentation, DeepLab, Dice loss Soeresen Dice Coeff
* RCNN, YOLO
* Neural style transfer
* Caps Nets
