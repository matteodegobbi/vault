{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Regression on House Pricing Dataset with SVM\n",
    "We consider a reduced version of a dataset containing house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n",
    "\n",
    "https://www.kaggle.com/harlfoxem/housesalesprediction\n",
    "\n",
    "For each house we know 18 house features (e.g., number of bedrooms, number of bathrooms, etc.) plus its price, that is what we would like to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In the notebook you will first:\n",
    "- split the data into training, validation, and test\n",
    "- standardize the data\n",
    "\n",
    "You will then be asked to learn various SVM models, in particular:\n",
    "- for each of the kernels ‘linear’, ‘poly’, ‘rbf’, and ‘sigmoid’, you will learn the best model having to choose among various values of some hyperparameters; the choice of hyperparameters must be done with 5-fold cross-validation\n",
    "- choose the best kernel, using a validation approach (not cross-validation)\n",
    "- learn the best SVM model overall\n",
    "\n",
    "You will then be asked to estimate the generalization error of the best SVM model you report. \n",
    "\n",
    "At the end, just for comparison, you will alsk be asked to learn a standard linear regression model (with squared loss), and estimate its generalization error.\n",
    "\n",
    "### IMPORTANT\n",
    "- Note that in each of the above steps you will have to choose the appropriate split of the data (see the first bullet point above)\n",
    "- The code should run without requiring modifications even if some best choice of parameters, changes; for example, you should not pass the best value of hyperparameters \"manually\" (i.e., passing the values as input parameters to the models). The only exception is in the TO DO titled 'ANSWER THE FOLLOWING'\n",
    "- For SVM, since the values to be predicted are all in the thousands of dollars, you will need to always set epsilon=1000\n",
    "- Do not change the printing instructions (other than adding the correct variable name for your code), and do not add printing instructions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - INSERT YOUR NUMERO DI MATRICOLA BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#put here your ``numero di matricola''\n",
    "numero_di_matricola = 2009765# COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import all packages needed\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The code below loads the data and remove samples with missing values. It also prints the number of samples in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 3164\n"
     ]
    }
   ],
   "source": [
    "#load the data - do not change the path below!\n",
    "df = pd.read_csv('kc_house_data.csv', sep = ',')\n",
    "\n",
    "#remove the data samples with missing values (NaN)\n",
    "df = df.dropna() \n",
    "\n",
    "Data = df.values\n",
    "m = Data.shape[0]\n",
    "Y = Data[:m,2]\n",
    "X = Data[:m,3:]\n",
    "\n",
    "print(\"Total number of samples:\",m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - SPLIT DATA INTO TRAINING, VALIDATION, AND TESTING, WITH THE FOLLOWING PERCENTAGES: 60%, 20%, 20%\n",
    "\n",
    "Use the train_test_split function from sklearn.model_selection to do it; in every call fix random_state to your numero_di_matricola. At the end, you should store the data in the following variables:\n",
    "- Xtrain, Ytrain: training data\n",
    "- Xval, Yval: validation data\n",
    "- Xtrain_val, Ytrain_val: training and validation data\n",
    "- Xtest, Ytest: test data\n",
    "\n",
    "The code then prints the number of samples in Xtrain, Xval, Xtrain_val, and Xtest\n",
    "\n",
    "IMPORTANT:\n",
    "- first split the data into training+validation and test; the first part of the data in output from train_test_split must correspond to the training+validation\n",
    "- then split training+validation into training and validation; the first part of the data in output from train_test_split must correspond to the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  1898\n",
      "Validation size:  633\n",
      "Training and validation size 2531\n",
      "Test size 633\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE\n",
    "m_train = int(0.6*m)\n",
    "m_val = int((m-m_train)/2.0)\n",
    "m_test = m - m_train - m_val \n",
    "\n",
    "Xtrain_val,Xtest,Ytrain_val,Ytest = train_test_split(X,Y,test_size=m_test/m, random_state=numero_di_matricola)\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(Xtrain_val,Ytrain_val,test_size=m_val/(m_val+m_train),random_state=numero_di_matricola)\n",
    "#######\n",
    "print(\"Training size: \", Xtrain.shape[0])\n",
    "print(\"Validation size: \", Xval.shape[0])\n",
    "print(\"Training and validation size\",Xtrain_val.shape[0])\n",
    "print(\"Test size\",Xtest.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - STANDARDIZE THE DATA\n",
    "\n",
    "Standardize the data using the preprocessing.StandardScaler from scikit learn.\n",
    "\n",
    "If V is the name of the variable storing part of the data, the corresponding standardized version should be stored in V_scaled. For example, the scaled version of Xtrain should be stored in Xtrain_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COMPLETE\n",
    "scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "Xtrain_scaled= scaler.transform(Xtrain)\n",
    "Xval_scaled = scaler.transform(Xval)\n",
    "Xtrain_val_scaled = scaler.transform(Xtrain_val)\n",
    "Xtest_scaled = scaler.transform(Xtest)\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SVM models: learning the best model for each kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - CHOOSE THE BEST HYPERPARAMETERS FOR LINEAR KERNEL\n",
    "\n",
    "Consider svm.SVR and linear kernel. Consider the following hyperparameters and their values:\n",
    "- C: 0.1, 1, 10, 100, 1000\n",
    "\n",
    "Leave all other input parameters to default. \n",
    "\n",
    "Find the best value of the hyperparameters using 5-fold cross validation. Use model_selection.GridSearchCV to perform the cross-validation.\n",
    "\n",
    "Print the best value of the hyperparameters (they are in the attribute best_params_ from GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear SVM\n",
      "Best value for hyperparameters:  {'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLinear SVM\")\n",
    "# COMPLETE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params5fold = {'C':[0.1, 1, 10, 100, 1000]}\n",
    "lin_svm = svm.SVR(kernel='linear',epsilon=1000)\n",
    "lin_svm5fold = GridSearchCV(lin_svm,param_grid=params5fold,cv=5)\n",
    "lin_svm5fold.fit(Xtrain_scaled,Ytrain)\n",
    "####################\n",
    "print(\"Best value for hyperparameters: \", lin_svm5fold.best_params_)# COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - LEARN A MODEL WITH LINEAR KERNEL AND BEST CHOICE OF HYPERPARAMETERS\n",
    "\n",
    "This model will be compared with the best models with other kernels using validation (not cross validation).\n",
    "\n",
    "DO NOT PASS PARAMETERS BY HARD-CODING THEM IN THE CODE.\n",
    "\n",
    "Print the training score of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.6442403465942954\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE\n",
    "best_lin_svm = svm.SVR(kernel='linear',epsilon=1000,C=lin_svm5fold.best_params_['C'])\n",
    "best_lin_svm.fit(Xtrain_scaled,Ytrain)\n",
    "#################\n",
    "print(\"Training score: \",best_lin_svm.score(Xtrain_scaled,Ytrain)) # COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - CHOOSE THE BEST HYPERPARAMETERS FOR POLY KERNEL\n",
    "\n",
    "Consider svm.SVR and polynomial kernel. Consider the following hyperparameters and their values:\n",
    "- C: 0.1, 1, 10, 100, 1000\n",
    "- degree: 2, 3, 4\n",
    "\n",
    "Leave all other input parameters to default. \n",
    "\n",
    "Find the best value of the hyperparameters using 5-fold cross validation. Use model_selection.GridSearchCV to perform the cross-validation.\n",
    "\n",
    "Print the best value of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poly SVM\n",
      "Best value for hyperparameters:  {'C': 1000, 'degree': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPoly SVM\")\n",
    "# COMPLETE\n",
    "params5fold = {'C':[0.1, 1, 10, 100, 1000],'degree':[2,3,4]}\n",
    "poly_svm = svm.SVR(kernel='poly',epsilon=1000)\n",
    "poly_svm5fold = GridSearchCV(poly_svm,param_grid=params5fold,cv=5)\n",
    "poly_svm5fold.fit(Xtrain_scaled,Ytrain)\n",
    "\n",
    "#########\n",
    "print(\"Best value for hyperparameters: \",poly_svm5fold.best_params_ ) # COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO - LEARN A MODEL WITH POLY KERNEL AND BEST CHOICE OF HYPERPARAMETERS\n",
    "\n",
    "This model will be compared with the best models with other kernels using validation (not cross validation).\n",
    "\n",
    "DO NOT PASS PARAMETERS BY HARD-CODING THEM IN THE CODE.\n",
    "\n",
    "Print the training score of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.5455405321232193\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE\n",
    "best_poly_svm = svm.SVR(kernel='poly',epsilon=1000,\n",
    "                        C=poly_svm5fold.best_params_['C'],\n",
    "                        degree=poly_svm5fold.best_params_['degree'])\n",
    "best_poly_svm.fit(Xtrain_scaled,Ytrain)\n",
    "################\n",
    "print(\"Training score: \",best_poly_svm.score(Xtrain_scaled,Ytrain)) # COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - CHOOSE THE BEST HYPERPARAMETERS FOR RBF KERNEL\n",
    "\n",
    "Consider svm.SVR and RBF kernel. Consider the following hyperparameters and their values:\n",
    "- C: 0.1, 1, 10, 100, 1000\n",
    "- gamma: 0.01\n",
    "\n",
    "Leave all other input parameters to default. \n",
    "\n",
    "Find the best value of the hyperparameters using 5-fold cross validation. Use model_selection.GridSearchCV to perform the cross-validation.\n",
    "\n",
    "Print the best value of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RBF SVM\n",
      "Best value for hyperparameters:  {'C': 1000, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRBF SVM\")\n",
    "# COMPLETE\n",
    "params5fold = {'C':[0.1, 1, 10, 100, 1000],'gamma':[0.01]}\n",
    "rbf_svm = svm.SVR(kernel='rbf',epsilon=1000)\n",
    "rbf_svm5fold = GridSearchCV(rbf_svm,param_grid=params5fold,cv=5)\n",
    "rbf_svm5fold.fit(Xtrain_scaled,Ytrain)\n",
    "############################33\n",
    "print(\"Best value for hyperparameters: \",rbf_svm5fold.best_params_ ) # COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - LEARN A MODEL WITH RBF KERNEL AND BEST CHOICE OF HYPERPARAMETERS\n",
    "\n",
    "This model will be compared with the best models with other kernels using validation (not cross validation).\n",
    "\n",
    "DO NOT PASS PARAMETERS BY HARD-CODING THEM IN THE CODE.\n",
    "\n",
    "Print the training score of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.13405559345472584\n"
     ]
    }
   ],
   "source": [
    "#COMPLETE \n",
    "best_rbf_svm = svm.SVR(kernel='rbf',epsilon=1000,C=rbf_svm5fold.best_params_['C'],gamma=rbf_svm5fold.best_params_['gamma'])\n",
    "best_rbf_svm.fit(Xtrain_scaled,Ytrain)\n",
    "################\n",
    "print(\"Training score: \",best_rbf_svm.score(Xtrain_scaled,Ytrain)) # COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO - CHOOSE THE BEST HYPERPARAMETERS FOR SIGMOID KERNEL\n",
    "\n",
    "Consider svm.SVR and sigmoid kernel. Consider the following hyperparameters and their values:\n",
    "- C: 0.1, 1, 10, 100, 1000\n",
    "- gamma: 0.01\n",
    "- coef0: 0, 1\n",
    "\n",
    "Leave all other input parameters to default. \n",
    "\n",
    "Find the best value of the hyperparameters using 5-fold cross validation. Use model_selection.GridSearchCV to perform the cross-validation.\n",
    "\n",
    "Print the best value of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sigmoid SVM\n",
      "Best value for hyperparameters:  {'C': 1000, 'coef0': 0, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSigmoid SVM\")\n",
    "# COMPLETE\n",
    "params5fold = {'C':[0.1, 1, 10, 100, 1000],'gamma':[0.01],'coef0':[0,1]}\n",
    "sig_svm = svm.SVR(kernel='sigmoid',epsilon=1000)\n",
    "sig_svm5fold = GridSearchCV(sig_svm,param_grid=params5fold,cv=5)\n",
    "sig_svm5fold.fit(Xtrain_scaled,Ytrain)\n",
    "########3\n",
    "print(\"Best value for hyperparameters: \",sig_svm5fold.best_params_ ) # COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO - LEARN A MODEL WITH SIGMOID KERNEL AND BEST CHOICE OF HYPERPARAMETERS\n",
    "\n",
    "This model will be compared with the best models with other kernels using validation (not cross validation).\n",
    "\n",
    "DO NOT PASS PARAMETERS BY HARD-CODING THEM IN THE CODE.\n",
    "\n",
    "Print the training score of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.11850331447200224\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE\n",
    "best_sig_svm = svm.SVR(kernel='sigmoid',epsilon=1000,\n",
    "                       C=sig_svm5fold.best_params_['C'],\n",
    "                       gamma=sig_svm5fold.best_params_['gamma'],\n",
    "                       coef0=sig_svm5fold.best_params_['coef0'])\n",
    "best_sig_svm.fit(Xtrain_scaled,Ytrain)\n",
    "################\n",
    "print(\"Training score: \",best_sig_svm.score(Xtrain_scaled,Ytrain)) # COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO - USE VALIDATION TO CHOOSE THE BEST MODEL AMONG THE ONES LEARNED FOR THE VARIOUS KERNELS\n",
    "\n",
    "Use validation to choose the best model among the four ones (one for each kernel) you have learned above.\n",
    "\n",
    "Print, following exactly the order described here, with 1 value for each line:\n",
    "- the validation score of SVM with linear kernel (the template below does not include such print)\n",
    "- the validation score of SVM with polynomial kernel (the template below does not include such print)\n",
    "- the validation score of SVM with rbf kernel (the template below does not include such print)\n",
    "- the validation score of SVM with sigmoid kernel (the template below does not include such print)\n",
    "- the best kernel (e.g., sigmoid) \n",
    "- the validation score of the best kernel \n",
    "\n",
    "For the first 4 prints, use the format: \"kernel validation score: \". For example, for linear kernel \"Linear validation score: \", for rbf \"rbf validation score: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION TO CHOOSE SVM KERNEL\n",
      "Linear validation score: 0.6064628882587209\n",
      "Poly validation score: 0.5871767593074817\n",
      "rbf validation score:0.11520512063453225\n",
      "Sigmoid validation score: 0.1077934931772756\n",
      "Best kernel:  linear\n",
      "Validation score of best kernel:  0.6064628882587209\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVALIDATION TO CHOOSE SVM KERNEL\")\n",
    "\n",
    "# COMPLETE - INCLUDING THE FIRST 4 PRINT FROM THE LIST ABOVE\n",
    "lin_val_score = best_lin_svm.score(Xval_scaled,Yval)\n",
    "poly_val_score = best_poly_svm.score(Xval_scaled,Yval)\n",
    "rbf_val_score = best_rbf_svm.score(Xval_scaled,Yval)\n",
    "sig_val_score = best_sig_svm.score(Xval_scaled,Yval)\n",
    "validation_scores = {\"linear\":lin_val_score,\n",
    "                     \"poly\":poly_val_score,\n",
    "                     \"rbf\":rbf_val_score,\n",
    "                     \"sigmoid\":sig_val_score\n",
    "                    }\n",
    "print(f\"Linear validation score: {lin_val_score}\")\n",
    "print(f\"Poly validation score: {poly_val_score}\")\n",
    "print(f\"rbf validation score:{ rbf_val_score}\")\n",
    "print(f\"Sigmoid validation score: {sig_val_score}\")\n",
    "best_validation_kernel = max(validation_scores,key=validation_scores.get)\n",
    "############################################################\n",
    "print(\"Best kernel: \", best_validation_kernel)# COMPLETE)\n",
    "print(\"Validation score of best kernel: \", validation_scores[best_validation_kernel])# COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO - LEARN THE FINAL MODEL FOR WHICH YOU WANT TO ESTIMATE THE GENERALIZATION ERROR\n",
    "\n",
    "Learn the final model (i.e., the one you would use to make predictions about future data).\n",
    "\n",
    "Print the score of the model on the data used to learn it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING SCORE BEST MODEL\n",
      "Score of the best model on the data used to learn it:  0.6431316190704458\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTRAINING SCORE BEST MODEL\")\n",
    "# COMPLETE\n",
    "if best_validation_kernel == 'linear':\n",
    "    final_model = svm.SVR(kernel='linear',epsilon=1000,\n",
    "                          C=lin_svm5fold.best_params_['C'])\n",
    "elif best_validation_kernel == 'poly':\n",
    "    final_model = svm.SVR(kernel='poly',epsilon=1000,\n",
    "                            C=poly_svm5fold.best_params_['C'],\n",
    "                            degree=poly_svm5fold.best_params_['degree'])\n",
    "elif best_validation_kernel == 'rbf':\n",
    "    final_model = svm.SVR(kernel='rbf',epsilon=1000,\n",
    "                          C=rbf_svm5fold.best_params_['C'],\n",
    "                          gamma=rbf_svm5fold.best_params_['gamma'])\n",
    "else:\n",
    "    final_model= svm.SVR(kernel='sigmoid',epsilon=1000,\n",
    "                           C=sig_svm5fold.best_params_['C'],\n",
    "                           gamma=sig_svm5fold.best_params_['gamma'],\n",
    "                           coef0=sig_svm5fold.best_params_['coef0'])\n",
    "final_model.fit(Xtrain_val_scaled,Ytrain_val)\n",
    "#############################################\n",
    "print(\"Score of the best model on the data used to learn it: \", \n",
    "      final_model.score(Xtrain_val_scaled,Ytrain_val)) # COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO - PRINT THE ESTIMATE  OF THE GENERALIZATION ERROR FOR THE FINAL MODEL\n",
    "\n",
    "Print the estimate of the generalization \"score\" for the final model. The generalization \"score\" is the score computed on the data used to estimate the generalization error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERALIZATION SCORE BEST MODEL\n",
      "Estimate of the generalization score for best SVM model:  0.6190151303458201\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGENERALIZATION SCORE BEST MODEL\")\n",
    "\n",
    "print(\"Estimate of the generalization score for best SVM model: \",\n",
    "      final_model.score(Xtest_scaled,Ytest))# COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO - ANSWER THE FOLLOWING\n",
    "\n",
    "Print the training score (score on data used to train the model) and the generalization score (score on data used to estimate the generalization error) of the final SVM model THAT YOU OBTAIN WHEN YOU RUN THE CODE, one per line, printing the smallest one first. NOTE: THE VALUES HERE SHOULD BE HARDCODED\n",
    "\n",
    "Print you answer (yes/no) to the following question: does the relation (i.e., smaller, larger) between the training score and the generalization score agree with the theory?\n",
    "\n",
    "Print your motivation for the yes/no answer above, using at most 500 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANSWER\n",
      "Generalization score:  0.6190151303458201\n",
      "Training score:  0.6431316190704458\n",
      "yes\n",
      "The generalization score is lower than the training score.\n",
      "This is in agreement with the theory because it admits\n",
      "a generalization error bigger than the training error.\n",
      "This is not always the case, it could happen that a model performs better on unseen data than on the training set.\n",
      "However in practice it's common to have a lower generalization score than training score because of overfitting.\n",
      "Also we are only estimating the generalization error through the test set\n",
      "and we can't know it's real value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nANSWER\")\n",
    "\n",
    "#note that you may have to invert the order of the following 2 lines, print the smallest 1 first. THE VALUES HERE SHOULD BE HARD CODED!\n",
    "print(\"Generalization score: \",0.6190151303458201) # COMPLETE )\n",
    "print(\"Training score: \",0.6431316190704458 )# COMPLETE )\n",
    "\n",
    "#the following is a string with you anwer\n",
    "motivation = '''yes\\nThe generalization score is lower than the training score.\n",
    "This is in agreement with the theory because it admits\n",
    "a generalization error bigger than the training error.\n",
    "This is not always the case, it could happen that a model performs better on unseen data than on the training set.\n",
    "However in practice it's common to have a lower generalization score than training score because of overfitting.\n",
    "Also we are only estimating the generalization error through the test set\n",
    "and we can't know it's real value\n",
    "'''\n",
    "\n",
    "print(motivation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO: LEARN A STANDARD LINEAR MODEL\n",
    "Learn a standard linear model using scikit learn.\n",
    "\n",
    "Print the score of the model on the data used to learn it.\n",
    "\n",
    "Print the generalization \"score\" of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR MODEL\n",
      "Score of LR model on data used to learng it:  0.7146408582519962\n",
      "Generalization score of LR model:  0.7276703634497186\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLR MODEL\")\n",
    "# COMPLETE\n",
    "LR = linear_model.LinearRegression()\n",
    "LR.fit(Xtrain_val_scaled,Ytrain_val)\n",
    "######\n",
    "print(\"Score of LR model on data used to learng it: \",\n",
    "      LR.score(Xtrain_val_scaled,Ytrain_val) ) # COMPLETE)\n",
    "print(\"Generalization score of LR model: \",\n",
    "      LR.score(Xtest_scaled,Ytest))# COMPLETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
